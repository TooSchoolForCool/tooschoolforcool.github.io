---
layout: project
title: "M3Bench: Benchmarking Whole-Body Motion Generation for Mobile Manipulation in 3D Scenes"
related_publications: [zhang2025m3bench]
permalink: /papers/m3bench
---

<h5 style="text-align: center;">
Zeyu Zhang*, Sixu Yan*, Muzhi Han, Zaijin Wang, Xinggang Wang, Song-Chun Zhu, Hangxin Liu†
</h5>
<p style="text-align: center;">
*denotes joint first authors, †denotes corresponding author
</p>
<h5 style="text-align: center; color: #db4848;">
IEEE Robotics and Automation Letters (RA-L), 2025
</h5>

<p style="text-align: center;">
<a href="https://arxiv.org/pdf/2410.06678" class="btn btn-secondary rounded-pill">PDF</a>
<a href="https://github.com/TooSchoolForCool/M3Bench" class="btn btn-secondary rounded-pill">Code</a>
<a href="https://huggingface.co/datasets/M3Bench/M3Bench" class="btn btn-secondary rounded-pill">Dataset</a>
</p>

<div class="row mt-3">
    <div class="col-sm">
        {% include figure.liquid path="papers/2025-ral-m3bench/thumbnail.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    The M3Bench benchmark challenges mobile manipulators to generate whole-body motion trajectories for object manipulation in scenes. Given a 3D scan, a target segmentation mask, and a task description, the robot must understand its embodiment, environment, and task objectives to produce coordinated motions for picking or placing objects.
</div>

## Abstract

We propose M3Bench, a new benchmark for whole-body motion generation in mobile manipulation tasks. Given a 3D scene context, M3Bench requires an embodied agent to reason about its configuration, environmental constraints, and task objectives to generate coordinated whole-body motion trajectories for object rearrangement. M3Bench features 30,000 object rearrangement tasks across 119 diverse scenes, providing expert demonstrations generated by our newly developed M3BenchMaker, an automatic data generation tool that produces whole-body motion trajectories from high-level task instructions using only basic scene and robot information. Our benchmark includes various task splits to evaluate generalization across different dimensions and leverages realistic physics simulation for trajectory assessment. Extensive evaluation analysis reveals that state-of-the-art models struggle with coordinating base-arm motion while adhering to environmental and task-specific constraints, underscoring the need for new models to bridge this gap. By releasing M3Bench and M3BenchMaker at https://zeyuzhang.com/papers/m3bench, we aim to advance robotics research toward more adaptive and capable mobile manipulation in diverse, real-world environments.

## Demo

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://www.youtube.com/embed/TwJQnRm663M" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="M3Bench: Benchmarking Whole-body Motion Generation for Mobile Manipulation in 3D Scenes"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script><br/>

## BibTex

```bibtex
@article{zhang2025m3bench,
  title = {M3Bench: Benchmarking Whole-Body Motion Generation for Mobile Manipulation in 3D Scenes},
  author = {Zhang, Zeyu and Yan, Sixu and Han, Muzhi and Wang, Zaijin and Wang, Xinggang and Zhu, Song-Chun and Liu, Hangxin},
  journal = {IEEE Robotics and Automation Letters (RA-L)},
  year = {2025},
  publisher = {IEEE},
}
```
